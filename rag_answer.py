import streamlit as st
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import chromadb
from chromadb.config import Settings
import torch

client = chromadb.EphemeralClient()

# ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿è¡¨ç¤º
st.set_page_config(page_title="RAG QA Demo", layout="centered")
st.title("ğŸ§  RAG è³ªå•å¿œç­”ãƒ‡ãƒ¢")

# ãƒ¢ãƒ‡ãƒ«ã¨DBã®èª­ã¿è¾¼ã¿
@st.cache_resource
def load_resources():
    retriever = SentenceTransformer("all-MiniLM-L6-v2")
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
    model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
    client = chromadb.PersistentClient(path="vectorstore/chroma_db")
    collection = client.get_or_create_collection(name="pdf_chunks")
    return retriever, tokenizer, model, collection

retriever, tokenizer, model, collection = load_resources()

# å…¥åŠ›UI
st.subheader("ğŸ” è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
query = st.text_input("ä¾‹ï¼šWhat is Nomad Academy?")

if st.button("è³ªå•ã™ã‚‹") and query:
    with st.spinner("æ¤œç´¢ä¸­..."):
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆè¤‡æ•°ãƒãƒ£ãƒ³ã‚¯å–å¾—ï¼‰
        q_emb = retriever.encode([query]).tolist()[0]
        results = collection.query(query_embeddings=[q_emb], n_results=3)

        if not results["documents"][0]:
            st.error("é–¢é€£ã™ã‚‹æ–‡ç« ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            context = "\n\n".join(results["documents"][0])

            # FLANç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ—¥æœ¬èªï¼‰
            prompt = f"""
ä»¥ä¸‹ã®æ–‡è„ˆã‚’å‚è€ƒã«ã—ã¦ã€æ¬¡ã®è³ªå•ã«æ—¥æœ¬èªã§ã‚ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚

æ–‡è„ˆ:
{context}

è³ªå•: {query}
ç­”ãˆ:
"""

            inputs = tokenizer(prompt, return_tensors="pt", truncation=True)
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=128,
                    temperature=0.7,
                    top_k=50,
                    top_p=0.95,
                )
            answer = tokenizer.decode(outputs[0], skip_special_tokens=True)

            # çµæœè¡¨ç¤º
            st.markdown("### ğŸ’¬ å›ç­”")
            st.success(answer.strip())
